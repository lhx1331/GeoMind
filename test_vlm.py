"""
VLM æµ‹è¯•è„šæœ¬

ç”¨äºæµ‹è¯• VLM æ¨¡å‹æ˜¯å¦èƒ½æ­£å¸¸å·¥ä½œï¼ŒåŒ…æ‹¬ï¼š
1. é…ç½®åŠ è½½
2. VLM åˆå§‹åŒ–
3. å›¾åƒåˆ†æ
4. è¾“å‡ºè§£æ
"""

import asyncio
import json
import sys
from pathlib import Path

from geomind.config.settings import get_settings
from geomind.models.vlm import create_vlm
from geomind.utils.logging import get_logger

logger = get_logger(__name__)


async def test_vlm_basic():
    """æµ‹è¯• VLM åŸºç¡€åŠŸèƒ½"""
    print("=" * 80)
    print("VLM åŸºç¡€åŠŸèƒ½æµ‹è¯•")
    print("=" * 80)
    
    # 1. åŠ è½½é…ç½®
    print("\n1. åŠ è½½é…ç½®...")
    try:
        settings = get_settings()
        vlm_config = settings.vlm
        print(f"   âœ… é…ç½®åŠ è½½æˆåŠŸ")
        print(f"   - Provider: {vlm_config.provider.value}")
        print(f"   - Model: {vlm_config.model_name}")
        print(f"   - Base URL: {vlm_config.base_url}")
        print(f"   - API Key: {'å·²é…ç½®' if vlm_config.api_key else 'æœªé…ç½®'}")
    except Exception as e:
        print(f"   âŒ é…ç½®åŠ è½½å¤±è´¥: {e}")
        return False
    
    # 2. åˆ›å»º VLM
    print("\n2. åˆ›å»º VLM...")
    try:
        vlm = await create_vlm(
            model_name=vlm_config.model_name,
            api_key=vlm_config.api_key,
            base_url=vlm_config.base_url,
        )
        print(f"   âœ… VLM åˆ›å»ºæˆåŠŸ")
    except Exception as e:
        print(f"   âŒ VLM åˆ›å»ºå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False
    
    # 3. æµ‹è¯•å›¾åƒè·¯å¾„
    print("\n3. æ£€æŸ¥æµ‹è¯•å›¾åƒ...")
    test_image = Path("D:/project/GeoMind/hollywood-sign-1598473_1920.jpg")
    if not test_image.exists():
        print(f"   âš ï¸  æµ‹è¯•å›¾åƒä¸å­˜åœ¨: {test_image}")
        print(f"   è¯·æä¾›å›¾åƒè·¯å¾„ä½œä¸ºå‘½ä»¤è¡Œå‚æ•°")
        if len(sys.argv) > 1:
            test_image = Path(sys.argv[1])
        else:
            return False
    print(f"   âœ… å›¾åƒå­˜åœ¨: {test_image}")
    
    # 4. è°ƒç”¨ VLM åˆ†æå›¾åƒ
    print("\n4. è°ƒç”¨ VLM åˆ†æå›¾åƒ...")
    try:
        prompt = """è¯·åˆ†æè¿™å¼ å›¾åƒï¼Œæå–åœ°ç†ç›¸å…³çš„çº¿ç´¢ä¿¡æ¯ã€‚

è¯·è¿”å› JSON æ ¼å¼ï¼š
{
  "ocr_texts": [{"text": "æ–‡æœ¬", "bbox": [x1,y1,x2,y2], "confidence": 0.9, "language": "en"}],
  "visual_features": [{"type": "ç±»å‹", "value": "æè¿°", "confidence": 0.85}],
  "metadata": {"time_of_day": "afternoon", "scene_type": "urban"}
}"""
        
        print(f"   æç¤ºé•¿åº¦: {len(prompt)} å­—ç¬¦")
        print(f"   æ­£åœ¨è°ƒç”¨ VLM API...")
        
        response = await vlm.analyze_image(
            image=str(test_image),
            prompt=prompt,
            system_prompt=None,
        )
        
        await vlm.cleanup()
        
        if not response.success:
            print(f"   âŒ VLM è°ƒç”¨å¤±è´¥: {response.error}")
            return False
        
        print(f"   âœ… VLM è°ƒç”¨æˆåŠŸ")
        print(f"   - å“åº”ç±»å‹: {type(response.data).__name__}")
        print(f"   - å“åº”é•¿åº¦: {len(str(response.data))} å­—ç¬¦")
        
    except Exception as e:
        print(f"   âŒ VLM è°ƒç”¨å¼‚å¸¸: {e}")
        import traceback
        traceback.print_exc()
        return False
    
    # 5. æ˜¾ç¤ºåŸå§‹è¾“å‡º
    print("\n5. VLM åŸå§‹è¾“å‡º:")
    print("-" * 80)
    raw_output = str(response.data)
    print(raw_output[:2000])  # æ˜¾ç¤ºå‰ 2000 å­—ç¬¦
    if len(raw_output) > 2000:
        print(f"\n... (è¿˜æœ‰ {len(raw_output) - 2000} å­—ç¬¦)")
    print("-" * 80)
    
    # 6. å°è¯•è§£æ JSON
    print("\n6. å°è¯•è§£æ JSON...")
    try:
        import re
        
        if isinstance(response.data, str):
            # å°è¯•ç›´æ¥è§£æ
            try:
                output_dict = json.loads(response.data)
                print("   âœ… ç›´æ¥ JSON è§£ææˆåŠŸ")
            except json.JSONDecodeError:
                # å°è¯•æå– JSON éƒ¨åˆ†
                json_match = re.search(r'```(?:json)?\s*(\{.*?\})\s*```', response.data, re.DOTALL)
                if json_match:
                    output_dict = json.loads(json_match.group(1))
                    print("   âœ… ä»ä»£ç å—ä¸­æå– JSON æˆåŠŸ")
                else:
                    json_match = re.search(r'\{.*\}', response.data, re.DOTALL)
                    if json_match:
                        output_dict = json.loads(json_match.group())
                        print("   âœ… ä»æ–‡æœ¬ä¸­æå– JSON æˆåŠŸ")
                    else:
                        print("   âŒ æ— æ³•æ‰¾åˆ° JSON æ ¼å¼")
                        return False
        else:
            output_dict = response.data
            print("   âœ… è¾“å‡ºå·²ç»æ˜¯å­—å…¸æ ¼å¼")
        
        # æ˜¾ç¤ºè§£æç»“æœ
        print("\n   è§£æç»“æœ:")
        print(f"   - OCR æ–‡æœ¬æ•°é‡: {len(output_dict.get('ocr_texts', []))}")
        print(f"   - è§†è§‰ç‰¹å¾æ•°é‡: {len(output_dict.get('visual_features', []))}")
        
        if output_dict.get('ocr_texts'):
            print("\n   OCR æ–‡æœ¬:")
            for i, ocr in enumerate(output_dict['ocr_texts'][:5], 1):
                print(f"     {i}. {ocr.get('text', 'N/A')} (ç½®ä¿¡åº¦: {ocr.get('confidence', 0):.2f})")
        
        if output_dict.get('visual_features'):
            print("\n   è§†è§‰ç‰¹å¾:")
            for i, vf in enumerate(output_dict['visual_features'][:5], 1):
                print(f"     {i}. {vf.get('type', 'N/A')}: {vf.get('value', 'N/A')} (ç½®ä¿¡åº¦: {vf.get('confidence', 0):.2f})")
        
        # ä¿å­˜å®Œæ•´è¾“å‡ºåˆ°æ–‡ä»¶
        output_file = Path("vlm_output.json")
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(output_dict, f, ensure_ascii=False, indent=2)
        print(f"\n   âœ… å®Œæ•´è¾“å‡ºå·²ä¿å­˜åˆ°: {output_file}")
        
        return True
        
    except Exception as e:
        print(f"   âŒ JSON è§£æå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


async def test_vlm_with_perception_prompt():
    """ä½¿ç”¨ Perception æç¤ºæ¨¡æ¿æµ‹è¯• VLM"""
    print("\n" + "=" * 80)
    print("ä½¿ç”¨ Perception æç¤ºæ¨¡æ¿æµ‹è¯•")
    print("=" * 80)
    
    try:
        from geomind.prompts.perception import render_perception_prompt
        
        # ç”Ÿæˆæç¤º
        prompt = render_perception_prompt(context=None)
        print(f"\næç¤ºé•¿åº¦: {len(prompt)} å­—ç¬¦")
        print(f"æç¤ºé¢„è§ˆ:\n{prompt[:500]}...")
        
        # æµ‹è¯•å›¾åƒ
        test_image = Path("D:/project/GeoMind/hollywood-sign-1598473_1920.jpg")
        if len(sys.argv) > 1:
            test_image = Path(sys.argv[1])
        
        if not test_image.exists():
            print(f"âš ï¸  å›¾åƒä¸å­˜åœ¨: {test_image}")
            return False
        
        # åˆ›å»º VLM
        settings = get_settings()
        vlm_config = settings.vlm
        vlm = await create_vlm(
            model_name=vlm_config.model_name,
            api_key=vlm_config.api_key,
            base_url=vlm_config.base_url,
        )
        
        # è°ƒç”¨ VLM
        print("\nè°ƒç”¨ VLM...")
        response = await vlm.analyze_image(
            image=str(test_image),
            prompt=prompt,
            system_prompt=None,
        )
        
        await vlm.cleanup()
        
        if not response.success:
            print(f"âŒ è°ƒç”¨å¤±è´¥: {response.error}")
            return False
        
        print(f"âœ… è°ƒç”¨æˆåŠŸ")
        print(f"\nåŸå§‹è¾“å‡º:\n{str(response.data)[:1000]}...")
        
        return True
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


async def main():
    """ä¸»å‡½æ•°"""
    print("\n" + "=" * 80)
    print("VLM æµ‹è¯•è„šæœ¬")
    print("=" * 80)
    print("\nç”¨æ³•: python test_vlm.py [å›¾åƒè·¯å¾„]")
    print("ç¤ºä¾‹: python test_vlm.py D:/project/GeoMind/hollywood-sign-1598473_1920.jpg\n")
    
    # æµ‹è¯• 1: åŸºç¡€åŠŸèƒ½
    result1 = await test_vlm_basic()
    
    # æµ‹è¯• 2: ä½¿ç”¨ Perception æç¤ºæ¨¡æ¿
    if result1:
        result2 = await test_vlm_with_perception_prompt()
    else:
        result2 = False
    
    # æ€»ç»“
    print("\n" + "=" * 80)
    print("æµ‹è¯•æ€»ç»“")
    print("=" * 80)
    print(f"åŸºç¡€åŠŸèƒ½æµ‹è¯•: {'âœ… é€šè¿‡' if result1 else 'âŒ å¤±è´¥'}")
    print(f"Perception æç¤ºæµ‹è¯•: {'âœ… é€šè¿‡' if result2 else 'âŒ å¤±è´¥'}")
    
    if result1 and result2:
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼VLM å·¥ä½œæ­£å¸¸ã€‚")
        return 0
    else:
        print("\nâš ï¸  éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥é…ç½®å’Œ API è¿æ¥ã€‚")
        return 1


if __name__ == "__main__":
    exit_code = asyncio.run(main())
    sys.exit(exit_code)

